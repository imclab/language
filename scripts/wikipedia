#!/usr/bin/env ruby
# encoding: utf-8

#########################################################################################
#                         							        #
#  quick script for extracting texts from downloaded wikipedia articles (output: json)  #
#										        #
#  scripts/wikipedia resources/[language]/wikipedia resources/[language]/	        #
#										        #
#########################################################################################

begin

	require 'nokogiri'

	require 'oj'

rescue LoadError

	puts ':('

	exit()

end

files, articles, total_paragraphs, total_words = Dir[ File.join( ARGV[0], '*' ) ], {}, 0, 0

files.each do |article|

	article_name = File.basename( article )

	articles.store( article_name, [] )

	html = Nokogiri::HTML( File.read(article) )

	html.css('p').each do |paragraph|

		articles[article_name] << paragraph.text

		total_paragraphs += 1

		total_words += paragraph.text.split.size

	end

end

open( File.join(ARGV[1], 'wikipedia.json'), 'w') do |f|

	f.print( Oj.dump(articles) )

end

puts "--- total articles: #{articles.size}, paragraphs: #{total_paragraphs}, words: #{total_words}"
